{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Phase 1: Dataset Preparation & Environment Setup\n",
    "Outdoor Object Detection & Face Recognition System\n",
    "\n",
    "This notebook handles:\n",
    "- Environment setup and dependency installation\n",
    "- Dataset download (LFW, WiderFace, RTTS, BDD100K)\n",
    "- Preprocessing (resize to 640x640, train/val/test split)\n",
    "- Data augmentation (fog, rain, low-light, motion blur)\n",
    "- Dataset statistics and verification\n",
    "\n",
    "**Runtime**: GPU (T4) recommended for faster processing\n",
    "**Storage**: Results saved to Google Drive"
   ],
   "metadata": {
    "id": "title-overview"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "PROJECT_DIR = '/content/drive/MyDrive/computer_vision'\n",
    "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "print(f\"Project directory: {PROJECT_DIR}\")"
   ],
   "metadata": {
    "id": "mount-drive"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content\n",
    "!rm -rf computer_vision_expirement\n",
    "!git clone https://github.com/Ib-Programmer/computer_vision_expirement.git\n",
    "%cd computer_vision_expirement\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q gdown"
   ],
   "metadata": {
    "id": "clone-install"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Dataset Download"
   ],
   "metadata": {
    "id": "section-download"
   }
  },
  {
   "cell_type": "code",
   "source": "%cd /content/computer_vision_expirement\n!python scripts/download_datasets.py",
   "metadata": {
    "id": "download-datasets"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Preprocessing"
   ],
   "metadata": {
    "id": "section-preprocess"
   }
  },
  {
   "cell_type": "code",
   "source": "%cd /content/computer_vision_expirement\n!python scripts/preprocess_data.py",
   "metadata": {
    "id": "run-preprocess"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 1.3 Augmentation Preview (Visual Only)\nAugmentations (fog, rain, low-light, motion blur, combined) are applied **on-the-fly during training** in Phase 3.\nThis saves ~35GB of disk space and gives better results (different random augmentation every epoch).\n\nBelow we generate a small visual preview to verify the augmentations look correct.",
   "metadata": {
    "id": "section-augmentation"
   }
  },
  {
   "cell_type": "code",
   "source": "%cd /content/computer_vision_expirement\n!pip install -q albumentations\n\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport albumentations as A\nimport glob\n\n# Define outdoor augmentations (same ones used in Phase 3 training)\naugmentations = {\n    'fog': A.RandomFog(fog_coef_lower=0.3, fog_coef_upper=0.7, alpha_coef=0.08, p=1.0),\n    'rain': A.RandomRain(slant_lower=-10, slant_upper=10, drop_length=20, drop_width=1,\n                         drop_color=(200, 200, 200), blur_value=3, brightness_coefficient=0.7, p=1.0),\n    'low_light': A.RandomBrightnessContrast(brightness_limit=(-0.5, -0.2), contrast_limit=(-0.3, 0.0), p=1.0),\n    'motion_blur': A.MotionBlur(blur_limit=(7, 15), p=1.0),\n    'combined': A.Compose([\n        A.OneOf([\n            A.RandomFog(fog_coef_lower=0.2, fog_coef_upper=0.5, alpha_coef=0.08, p=1.0),\n            A.RandomRain(slant_lower=-10, slant_upper=10, drop_length=20, drop_width=1,\n                         drop_color=(200, 200, 200), blur_value=3, brightness_coefficient=0.7, p=1.0),\n        ], p=0.5),\n        A.OneOf([\n            A.RandomBrightnessContrast(brightness_limit=(-0.4, -0.1), contrast_limit=(-0.2, 0.0), p=1.0),\n            A.MotionBlur(blur_limit=(7, 12), p=1.0),\n        ], p=0.5),\n    ]),\n}\n\n# Find sample images from preprocessed datasets\nPROJECT_DIR = '/content/drive/MyDrive/computer_vision'\nsample_paths = glob.glob(f'{PROJECT_DIR}/datasets/*_processed/train/*.jpg')[:3]\nif not sample_paths:\n    sample_paths = glob.glob(f'/content/computer_vision_expirement/datasets/*_processed/train/*.jpg')[:3]\n\nif sample_paths:\n    aug_names = list(augmentations.keys())\n    fig, axes = plt.subplots(len(sample_paths), len(aug_names) + 1, figsize=(20, 4 * len(sample_paths)))\n    if len(sample_paths) == 1:\n        axes = [axes]\n\n    for row, img_path in enumerate(sample_paths):\n        img = cv2.imread(img_path)\n        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        axes[row][0].imshow(img_rgb)\n        axes[row][0].set_title('Original', fontsize=10)\n        axes[row][0].axis('off')\n\n        for col, aug_name in enumerate(aug_names, 1):\n            transform = augmentations[aug_name]\n            if isinstance(transform, A.Compose):\n                aug_img = transform(image=img_rgb)['image']\n            else:\n                t = A.Compose([transform])\n                aug_img = t(image=img_rgb)['image']\n            axes[row][col].imshow(aug_img)\n            axes[row][col].set_title(aug_name, fontsize=10)\n            axes[row][col].axis('off')\n\n    plt.suptitle('Augmentation Preview (applied on-the-fly during Phase 3 training)', fontsize=14)\n    plt.tight_layout()\n    plt.savefig(f'{PROJECT_DIR}/results/augmentation_preview.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    print(\"Preview saved. Full augmentations run on-the-fly in Phase 3.\")\nelse:\n    print(\"No preprocessed images found. Run preprocessing first.\")",
   "metadata": {
    "id": "run-augmentation"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 Dataset Statistics"
   ],
   "metadata": {
    "id": "section-stats"
   }
  },
  {
   "cell_type": "code",
   "source": "%cd /content/computer_vision_expirement\n!python scripts/dataset_stats.py",
   "metadata": {
    "id": "run-stats"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 1.5 Save to Google Drive (lightweight â€” results only)\nDatasets stay on Colab's local disk (fast SSD). They get re-downloaded each session (~20 min).\nOnly small results (stats CSV, augmentation preview) are saved to Drive to preserve space.",
   "metadata": {
    "id": "section-save"
   }
  },
  {
   "cell_type": "code",
   "source": "import os\n\nPROJECT_DIR = '/content/drive/MyDrive/computer_vision'\nRESULTS_DIR = f'{PROJECT_DIR}/results/phase1'\nos.makedirs(RESULTS_DIR, exist_ok=True)\n\n# Save only lightweight results to Drive (stats, preview image)\nimport shutil\nimport glob\n\n# Copy stats CSV if generated\nfor f in glob.glob('/content/computer_vision_expirement/datasets/*stats*'):\n    shutil.copy(f, RESULTS_DIR)\n\n# Copy augmentation preview\npreview = f'{PROJECT_DIR}/results/augmentation_preview.png'\nif os.path.exists(preview):\n    print(f\"Augmentation preview saved: {preview}\")\n\n# Show what's on local disk (NOT copied to Drive)\nimport subprocess\nlocal_size = subprocess.run(['du', '-sh', '/content/computer_vision_expirement/datasets'],\n                            capture_output=True, text=True)\nprint(f\"\\nLocal datasets (Colab disk, NOT on Drive): {local_size.stdout.strip()}\")\n\ndrive_size = subprocess.run(['du', '-sh', PROJECT_DIR], capture_output=True, text=True)\nprint(f\"Drive usage: {drive_size.stdout.strip()}\")\n\nprint(f\"\"\"\nPhase 1 Complete!\n\nStorage strategy:\n  - Datasets stay on Colab local disk (re-download each session, ~20 min)\n  - Only trained models + metrics saved to Drive (<1GB total)\n  - Augmentations applied on-the-fly in Phase 3 (zero storage)\n  - Free Drive (15GB) is more than enough!\n\nNext: Open Phase2_Image_Enhancement.ipynb\n\"\"\")",
   "metadata": {
    "id": "save-to-drive"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Next Steps\n- Open **Phase2_Image_Enhancement.ipynb** to evaluate enhancement models\n- Each phase re-downloads datasets to Colab's fast local disk (~20 min)\n- Only results (models, metrics) are saved to Google Drive",
   "metadata": {
    "id": "next-steps"
   }
  }
 ]
}