{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 1: Dataset Preparation & Environment Setup\n",
        "Outdoor Object Detection & Face Recognition System\n",
        "\n",
        "This notebook handles:\n",
        "- Environment setup and dependency installation\n",
        "- Dataset download (LFW, WiderFace, RTTS, BDD100K)\n",
        "- Preprocessing (resize to 640x640, train/val/test split)\n",
        "- Data augmentation (fog, rain, low-light, motion blur)\n",
        "- Dataset statistics and verification\n",
        "\n",
        "**Runtime**: GPU (T4) recommended for faster processing\n",
        "**Storage**: Results saved to Google Drive"
      ],
      "metadata": {
        "id": "title-overview"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "PROJECT_DIR = '/content/drive/MyDrive/computer_vision'\n",
        "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
        "print(f\"Project directory: {PROJECT_DIR}\")"
      ],
      "metadata": {
        "id": "mount-drive",
        "outputId": "541defcd-bf6b-4dd7-9379-e89bf22640c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Project directory: /content/drive/MyDrive/computer_vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf computer_vision_expirement\n",
        "!git clone https://github.com/Ib-Programmer/computer_vision_expirement.git\n",
        "%cd computer_vision_expirement\n",
        "!pip install -q -r requirements.txt\n",
        "!pip install -q gdown"
      ],
      "metadata": {
        "id": "clone-install",
        "outputId": "eb338d04-3023-4482-9964-acf37932fa50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'computer_vision_expirement'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 33 (delta 7), reused 28 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (33/33), 37.05 KiB | 2.18 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n",
            "/content/computer_vision_expirement\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.2/276.2 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.2/333.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.7/60.7 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.4/299.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.4/566.4 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.2.2 requires transformers<6.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Dataset Download"
      ],
      "metadata": {
        "id": "section-download"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/download_datasets.py"
      ],
      "metadata": {
        "id": "download-datasets",
        "outputId": "1a28b599-7c23-4b65-92e4-f4938580582f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase 1: Dataset Download\n",
            "Base directory: /content/computer_vision_expirement\n",
            "Datasets directory: /content/computer_vision_expirement/datasets\n",
            "\n",
            "============================================================\n",
            "DOWNLOADING: LFW (Labeled Faces in the Wild)\n",
            "============================================================\n",
            "  Trying sklearn.datasets.fetch_lfw_people...\n",
            "  Downloaded via sklearn: 13233 images\n",
            "  LFW download complete!\n",
            "  Location: /content/computer_vision_expirement/datasets/lfw\n",
            "\n",
            "============================================================\n",
            "DOWNLOADING: WiderFace\n",
            "============================================================\n",
            "  Downloading WIDER_train.zip from Google Drive...\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=15hGDLhsx8bLgLcIRD5DhYt5iBxnjNF1M\n",
            "From (redirected): https://drive.google.com/uc?id=15hGDLhsx8bLgLcIRD5DhYt5iBxnjNF1M&confirm=t&uuid=0ff59cff-9fb1-4d5b-83be-ebad0c51697a\n",
            "To: /content/computer_vision_expirement/datasets/widerface/WIDER_train.zip\n",
            "100% 1.47G/1.47G [00:20<00:00, 70.8MB/s]\n",
            "  Extracting WIDER_train.zip...\n",
            "  Extracted to: /content/computer_vision_expirement/datasets/widerface\n",
            "  Downloading WIDER_val.zip from Google Drive...\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1GUCogbp16PMGa39thoMMeWxp7Rp5oM8Q\n",
            "From (redirected): https://drive.google.com/uc?id=1GUCogbp16PMGa39thoMMeWxp7Rp5oM8Q&confirm=t&uuid=cf516867-8bca-4add-8741-600123b78474\n",
            "To: /content/computer_vision_expirement/datasets/widerface/WIDER_val.zip\n",
            "100% 363M/363M [00:03<00:00, 104MB/s]\n",
            "  Extracting WIDER_val.zip...\n",
            "  Extracted to: /content/computer_vision_expirement/datasets/widerface\n",
            "  Downloading wider_face_split.zip from Hugging Face mirror...\n",
            "  Downloading: https://huggingface.co/datasets/wider_face/resolve/main/data/wider_face_split.zip\n",
            "wider_face_split.zip: 3.60MB [00:00, 9.98MB/s]                \n",
            "  Saved to: /content/computer_vision_expirement/datasets/widerface/wider_face_split.zip\n",
            "  Extracting wider_face_split.zip...\n",
            "  Extracted to: /content/computer_vision_expirement/datasets/widerface\n",
            "  WiderFace download complete!\n",
            "  Location: /content/computer_vision_expirement/datasets/widerface\n",
            "\n",
            "============================================================\n",
            "DOWNLOADING: RTTS (Real-world Task-driven Testing Set)\n",
            "============================================================\n",
            "  Trying Kaggle API (tuncnguyn/rtts-dataset)...\n",
            "  Kaggle method failed: Could not find kaggle.json. Make sure it's located in /root/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/\n",
            "  Trying UT Austin Box mirror (official RESIDE-beta)...\n",
            "  Downloading: https://utexas.app.box.com/index.php?rm=box_download_shared_file&shared_name=2yekra41udg9rgyzi3ysi513cps621qz&file_id=f_766454923366\n",
            "RTTS: 1.07GB [00:32, 32.6MB/s]                \n",
            "  Saved to: /content/computer_vision_expirement/datasets/rtts/RTTS.zip\n",
            "  Extracting RTTS.zip...\n",
            "  Extracted to: /content/computer_vision_expirement/datasets/rtts\n",
            "  RTTS download complete!\n",
            "  Location: /content/computer_vision_expirement/datasets/rtts\n",
            "\n",
            "============================================================\n",
            "DOWNLOADING: BDD100K (Berkeley DeepDrive)\n",
            "============================================================\n",
            "  Downloading BDD100K Images (~6.5GB)...\n",
            "  Downloading: https://archive.org/download/bdd100k/bdd100k_images.zip\n",
            "bdd100k_images.zip: 6.94GB [02:54, 39.7MB/s]                \n",
            "  Saved to: /content/computer_vision_expirement/datasets/bdd100k/bdd100k_images.zip\n",
            "  Extracting bdd100k_images.zip...\n",
            "  Extracted to: /content/computer_vision_expirement/datasets/bdd100k\n",
            "  Downloading BDD100K Labels (~147MB)...\n",
            "  Downloading: https://archive.org/download/bdd100k/bdd100k_labels.zip\n",
            "bdd100k_labels.zip: 154MB [00:04, 32.3MB/s]               \n",
            "  Saved to: /content/computer_vision_expirement/datasets/bdd100k/bdd100k_labels.zip\n",
            "  Extracting bdd100k_labels.zip...\n",
            "  Extracted to: /content/computer_vision_expirement/datasets/bdd100k\n",
            "  BDD100K download complete! (110000 images found)\n",
            "  Location: /content/computer_vision_expirement/datasets/bdd100k\n",
            "\n",
            "============================================================\n",
            "DOWNLOAD SUMMARY\n",
            "============================================================\n",
            "  lfw          ->  13233 images found\n",
            "  widerface    ->  16106 images found\n",
            "  rtts         ->   4322 images found\n",
            "  bdd100k      -> 110000 images found\n",
            "\n",
            "Done! Next: run preprocess_data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Preprocessing"
      ],
      "metadata": {
        "id": "section-preprocess"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/preprocess_data.py"
      ],
      "metadata": {
        "id": "run-preprocess",
        "outputId": "82fc311b-2122-4d9e-c73f-fa62b1ceefc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase 1: Data Preprocessing\n",
            "Target size: (640, 640)\n",
            "Split ratio: {'train': 0.7, 'val': 0.15, 'test': 0.15}\n",
            "Chunk size: 200 images\n",
            "JPEG quality: 90\n",
            "\n",
            "============================================================\n",
            "PREPROCESSING: lfw\n",
            "============================================================\n",
            "  Found 13233 images\n",
            "  Chunk size: 200 images | JPEG quality: 90\n",
            "\n",
            "  train: 9263 images in 47 chunks\n",
            "    train: 100%|██████████████████████████| 9263/9263 [01:06<00:00, 139.40img/s]\n",
            "    -> processed: 9263 | skipped: 0 | failed: 0\n",
            "\n",
            "  val: 1984 images in 10 chunks\n",
            "    val: 100%|████████████████████████████| 1984/1984 [00:12<00:00, 160.82img/s]\n",
            "    -> processed: 1984 | skipped: 0 | failed: 0\n",
            "\n",
            "  test: 1986 images in 10 chunks\n",
            "    test: 100%|████████████████████████████| 1986/1986 [00:20<00:00, 97.01img/s]\n",
            "    -> processed: 1986 | skipped: 0 | failed: 0\n",
            "\n",
            "  ────────────────────────────────────────\n",
            "  lfw DONE\n",
            "    Total processed: 13233\n",
            "    Already existed: 0\n",
            "    Failed/corrupt:  0\n",
            "    train: 9263 images\n",
            "    val: 1984 images\n",
            "    test: 1986 images\n",
            "  Output: /content/computer_vision_expirement/datasets/lfw_processed\n",
            "\n",
            "============================================================\n",
            "PREPROCESSING: widerface\n",
            "============================================================\n",
            "  Found 16106 images\n",
            "  Chunk size: 200 images | JPEG quality: 90\n",
            "\n",
            "  train: 11274 images in 57 chunks\n",
            "    train: 100%|█████████████████████████| 11274/11274 [02:22<00:00, 79.28img/s]\n",
            "    -> processed: 11274 | skipped: 0 | failed: 0\n",
            "\n",
            "  val: 2415 images in 13 chunks\n",
            "    val: 100%|█████████████████████████████| 2415/2415 [00:27<00:00, 89.39img/s]\n",
            "    -> processed: 2415 | skipped: 0 | failed: 0\n",
            "\n",
            "  test: 2417 images in 13 chunks\n",
            "    test: 100%|████████████████████████████| 2417/2417 [00:26<00:00, 91.41img/s]\n",
            "    -> processed: 2417 | skipped: 0 | failed: 0\n",
            "\n",
            "  ────────────────────────────────────────\n",
            "  widerface DONE\n",
            "    Total processed: 16106\n",
            "    Already existed: 0\n",
            "    Failed/corrupt:  0\n",
            "    train: 11274 images\n",
            "    val: 2415 images\n",
            "    test: 2417 images\n",
            "  Output: /content/computer_vision_expirement/datasets/widerface_processed\n",
            "\n",
            "============================================================\n",
            "PREPROCESSING: rtts\n",
            "============================================================\n",
            "  Found 4322 images\n",
            "  Chunk size: 200 images | JPEG quality: 90\n",
            "\n",
            "  train: 3025 images in 16 chunks\n",
            "    train: 100%|███████████████████████████| 3025/3025 [05:18<00:00,  9.49img/s]\n",
            "    -> processed: 3025 | skipped: 0 | failed: 0\n",
            "\n",
            "  val: 648 images in 4 chunks\n",
            "    val: 100%|███████████████████████████████| 648/648 [01:07<00:00,  9.56img/s]\n",
            "    -> processed: 648 | skipped: 0 | failed: 0\n",
            "\n",
            "  test: 649 images in 4 chunks\n",
            "    test: 100%|██████████████████████████████| 649/649 [01:13<00:00,  8.80img/s]\n",
            "    -> processed: 649 | skipped: 0 | failed: 0\n",
            "\n",
            "  ────────────────────────────────────────\n",
            "  rtts DONE\n",
            "    Total processed: 4322\n",
            "    Already existed: 0\n",
            "    Failed/corrupt:  0\n",
            "    train: 3025 images\n",
            "    val: 648 images\n",
            "    test: 649 images\n",
            "  Output: /content/computer_vision_expirement/datasets/rtts_processed\n",
            "\n",
            "============================================================\n",
            "PREPROCESSING: bdd100k\n",
            "============================================================\n",
            "  Found 110000 images\n",
            "  Chunk size: 200 images | JPEG quality: 90\n",
            "\n",
            "  train: 77000 images in 385 chunks\n",
            "    train: 100%|█████████████████████████| 77000/77000 [15:45<00:00, 81.42img/s]\n",
            "    -> processed: 77000 | skipped: 0 | failed: 0\n",
            "\n",
            "  val: 16500 images in 83 chunks\n",
            "    val: 100%|███████████████████████████| 16500/16500 [03:08<00:00, 87.64img/s]\n",
            "    -> processed: 16500 | skipped: 0 | failed: 0\n",
            "\n",
            "  test: 16500 images in 83 chunks\n",
            "    test: 100%|██████████████████████████| 16500/16500 [03:25<00:00, 80.36img/s]\n",
            "    -> processed: 16500 | skipped: 0 | failed: 0\n",
            "\n",
            "  ────────────────────────────────────────\n",
            "  bdd100k DONE\n",
            "    Total processed: 110000\n",
            "    Already existed: 0\n",
            "    Failed/corrupt:  0\n",
            "    train: 77000 images\n",
            "    val: 16500 images\n",
            "    test: 16500 images\n",
            "  Output: /content/computer_vision_expirement/datasets/bdd100k_processed\n",
            "\n",
            "============================================================\n",
            "PREPROCESSING COMPLETE\n",
            "============================================================\n",
            "Next: run augment_data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Data Augmentation"
      ],
      "metadata": {
        "id": "section-augmentation"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/augment_data.py"
      ],
      "metadata": {
        "id": "run-augmentation",
        "outputId": "d681b5af-0a9b-4db6-da87-7ed4d1a88a6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/computer_vision_expirement/scripts/augment_data.py:33: UserWarning: Argument(s) 'fog_coef_lower, fog_coef_upper' are not valid for transform RandomFog\n",
            "  A.RandomFog(\n",
            "/content/computer_vision_expirement/scripts/augment_data.py:61: UserWarning: Argument(s) 'slant_lower, slant_upper' are not valid for transform RandomRain\n",
            "  A.RandomRain(\n",
            "/content/computer_vision_expirement/scripts/augment_data.py:77: UserWarning: Argument(s) 'fog_coef_lower, fog_coef_upper' are not valid for transform RandomFog\n",
            "  A.RandomFog(fog_coef_lower=0.2, fog_coef_upper=0.5, alpha_coef=0.08, p=1.0),\n",
            "/content/computer_vision_expirement/scripts/augment_data.py:78: UserWarning: Argument(s) 'slant_lower, slant_upper' are not valid for transform RandomRain\n",
            "  A.RandomRain(slant_lower=-10, slant_upper=10, drop_length=20, drop_width=1,\n",
            "/usr/local/lib/python3.12/dist-packages/albumentations/augmentations/blur/functional.py:232: UserWarning: blur_limit: Non-zero kernel sizes must be odd. Range (7, 12) automatically adjusted to (7, 13).\n",
            "  result = _ensure_odd_values(result, info.field_name)\n",
            "/content/computer_vision_expirement/scripts/augment_data.py:85: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n",
            "Phase 1: Data Augmentation\n",
            "Output directory: /content/computer_vision_expirement/outputs/augmented\n",
            "Chunk size: 150 images\n",
            "Augmentation types: ['fog', 'low_light', 'motion_blur', 'rain', 'combined']\n",
            "\n",
            "============================================================\n",
            "AUGMENTING: lfw\n",
            "============================================================\n",
            "  Split: train (9263 images)\n",
            "  Chunk size: 150 | Augmentations: ['fog', 'low_light', 'motion_blur', 'rain', 'combined']\n",
            "    fog: 9263 images in 62 chunks\n",
            "\r      fog:   0%|                                      | 0/9263 [00:00<?, ?img/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Dataset Statistics"
      ],
      "metadata": {
        "id": "section-stats"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/dataset_stats.py"
      ],
      "metadata": {
        "id": "run-stats"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Save to Google Drive"
      ],
      "metadata": {
        "id": "section-save"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "src = '/content/computer_vision_expirement/datasets'\n",
        "dst = f'{PROJECT_DIR}/datasets'\n",
        "\n",
        "if os.path.exists(dst):\n",
        "    print(f\"Datasets already exist at {dst}, skipping copy\")\n",
        "else:\n",
        "    print(f\"Copying datasets to Google Drive...\")\n",
        "    shutil.copytree(src, dst)\n",
        "    print(\"Done!\")\n",
        "\n",
        "# Also copy augmented outputs\n",
        "src_aug = '/content/computer_vision_expirement/outputs'\n",
        "dst_aug = f'{PROJECT_DIR}/outputs'\n",
        "if os.path.exists(src_aug):\n",
        "    if os.path.exists(dst_aug):\n",
        "        print(f\"Augmented data already exists at {dst_aug}, skipping copy\")\n",
        "    else:\n",
        "        print(f\"Copying augmented data to Google Drive...\")\n",
        "        shutil.copytree(src_aug, dst_aug)\n",
        "        print(\"Done!\")\n",
        "\n",
        "print(\"\\nPhase 1 Complete! Data saved to Google Drive.\")\n",
        "print(f\"Location: {PROJECT_DIR}\")"
      ],
      "metadata": {
        "id": "save-to-drive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next Steps\n",
        "- Open **Phase2_Image_Enhancement.ipynb** to evaluate enhancement models\n",
        "- Datasets are saved in Google Drive and will persist across sessions"
      ],
      "metadata": {
        "id": "next-steps"
      }
    }
  ]
}