{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Image Enhancement Evaluation\n",
    "Evaluating Restormer, FFA-Net, and Zero-DCE++ on degraded outdoor images.\n",
    "\n",
    "**Metrics**: PSNR, SSIM, NIQE, Inference Latency\n",
    "**Goal**: Select the best enhancement model for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "PROJECT_DIR = '/content/drive/MyDrive/computer_vision'\n",
    "DATASETS_DIR = f'{PROJECT_DIR}/datasets'\n",
    "RESULTS_DIR = f'{PROJECT_DIR}/results/phase2'\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "%cd /content\n",
    "!rm -rf computer_vision_expirement\n",
    "!git clone https://github.com/Ib-Programmer/computer_vision_expirement.git\n",
    "%cd computer_vision_expirement\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pyiqa basicsr einops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Load sample test images from each dataset\n",
    "def load_test_samples(dataset_dir, max_samples=50):\n",
    "    images = []\n",
    "    paths = sorted(glob.glob(f'{dataset_dir}/*_processed/test/*.jpg') + \n",
    "                   glob.glob(f'{dataset_dir}/*_processed/test/*.png'))\n",
    "    for p in paths[:max_samples]:\n",
    "        img = cv2.imread(p)\n",
    "        if img is not None:\n",
    "            images.append((p, img))\n",
    "    return images\n",
    "\n",
    "test_images = load_test_samples(DATASETS_DIR, max_samples=100)\n",
    "print(f\"Loaded {len(test_images)} test images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Setup Enhancement Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-DCE++ for low-light enhancement\n",
    "!pip install -q git+https://github.com/Li-Chongyi/Zero-DCE_extension.git 2>/dev/null || echo \"Installing Zero-DCE++ manually...\"\n",
    "\n",
    "# Download pretrained weights\n",
    "import gdown\n",
    "os.makedirs('weights', exist_ok=True)\n",
    "\n",
    "# Zero-DCE++ weights\n",
    "if not os.path.exists('weights/zero_dce_pp.pth'):\n",
    "    print(\"Downloading Zero-DCE++ weights...\")\n",
    "    gdown.download(\n",
    "        'https://drive.google.com/uc?id=1Y3FS0AzXRhp5UH6xLIhGKL5GsLqosmq',\n",
    "        'weights/zero_dce_pp.pth', quiet=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restormer for general image restoration\n",
    "!git clone https://github.com/swz30/Restormer.git 2>/dev/null || echo \"Restormer already cloned\"\n",
    "\n",
    "# Download deraining weights\n",
    "if not os.path.exists('weights/restormer_deraining.pth'):\n",
    "    print(\"Downloading Restormer weights...\")\n",
    "    gdown.download(\n",
    "        'https://drive.google.com/uc?id=1HGAsZgjNiNn3VKjRAqPIHULuZOQz0Nmq',\n",
    "        'weights/restormer_deraining.pth', quiet=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFA-Net for dehazing\n",
    "!git clone https://github.com/zhilin007/FFA-Net.git 2>/dev/null || echo \"FFA-Net already cloned\"\n",
    "\n",
    "if not os.path.exists('weights/ffa_net.pk'):\n",
    "    print(\"Downloading FFA-Net weights...\")\n",
    "    gdown.download(\n",
    "        'https://drive.google.com/uc?id=1GKByqOOIWRJZRsWEzfywGIWNxpm3JReq',\n",
    "        'weights/ffa_net.pk', quiet=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Run Enhancement & Measure Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyiqa\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Initialize no-reference metrics\n",
    "niqe_metric = pyiqa.create_metric('niqe', device='cuda' if __import__('torch').cuda.is_available() else 'cpu')\n",
    "\n",
    "def evaluate_image_quality(original, enhanced):\n",
    "    \"\"\"Calculate quality metrics between original and enhanced images.\"\"\"\n",
    "    # Convert to float\n",
    "    orig_f = original.astype(np.float64) / 255.0\n",
    "    enh_f = enhanced.astype(np.float64) / 255.0\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['psnr'] = psnr(orig_f, enh_f, data_range=1.0)\n",
    "    metrics['ssim'] = ssim(orig_f, enh_f, data_range=1.0, channel_axis=2)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def measure_inference_time(model_fn, image, n_runs=10):\n",
    "    \"\"\"Measure average inference time.\"\"\"\n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        start = time.time()\n",
    "        _ = model_fn(image)\n",
    "        times.append(time.time() - start)\n",
    "    return np.mean(times) * 1000  # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "# Process each test image through each model\n",
    "# Note: Actual model loading/inference code depends on model availability\n",
    "# This is the evaluation framework - adjust model paths as needed\n",
    "\n",
    "print(\"Running enhancement evaluation...\")\n",
    "print(\"This may take 10-30 minutes depending on GPU...\")\n",
    "\n",
    "# Placeholder for model inference functions\n",
    "# Each model's inference will be added when weights are confirmed available\n",
    "\n",
    "# For now, create the evaluation framework\n",
    "evaluation_df = pd.DataFrame(columns=['Model', 'Avg_PSNR', 'Avg_SSIM', 'Avg_NIQE', 'Avg_Latency_ms'])\n",
    "print(\"\\nEvaluation framework ready.\")\n",
    "print(\"Run each model section below to populate results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create comparison visualization\n",
    "def show_enhancement_comparison(original, enhanced_dict, title=\"Enhancement Comparison\"):\n",
    "    n = 1 + len(enhanced_dict)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(4*n, 4))\n",
    "    \n",
    "    axes[0].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    for i, (name, img) in enumerate(enhanced_dict.items(), 1):\n",
    "        axes[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axes[i].set_title(name)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{RESULTS_DIR}/enhancement_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualization functions ready.\")\n",
    "print(\"Results will be saved to:\", RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation results\n",
    "# evaluation_df.to_csv(f'{RESULTS_DIR}/enhancement_benchmark.csv', index=False)\n",
    "print(f\"\\nPhase 2 results saved to: {RESULTS_DIR}\")\n",
    "print(\"Next: Open Phase3_Object_Detection.ipynb\")"
   ]
  }
 ]
}