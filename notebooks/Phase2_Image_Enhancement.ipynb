{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ib-Programmer/computer_vision_expirement/blob/main/notebooks/Phase2_Image_Enhancement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjyLLtKP13Nw"
      },
      "source": [
        "# Phase 2: Image Enhancement Evaluation\n",
        "Evaluating Restormer, FFA-Net, and Zero-DCE++ on degraded outdoor images.\n",
        "\n",
        "**Metrics**: PSNR, SSIM, NIQE, Inference Latency\n",
        "**Goal**: Select the best enhancement model for the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TWhVymbG13Ny",
        "outputId": "2052d975-d749-4449-ce41-43c42ef3cf90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content\n",
            "Cloning into 'computer_vision_expirement'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 72 (delta 36), reused 49 (delta 20), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (72/72), 1.17 MiB | 5.78 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n",
            "/content/computer_vision_expirement\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.2/276.2 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m115.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.2/333.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.7/60.7 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.4/299.4 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.4/566.4 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.2.2 requires transformers<6.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "--- Downloading datasets to local disk ---\n",
            "Phase 1: Dataset Download\n",
            "Base directory: /content/computer_vision_expirement\n",
            "Datasets directory: /content/computer_vision_expirement/datasets\n",
            "\n",
            "============================================================\n",
            "DOWNLOADING: RTTS (Real-world Task-driven Testing Set)\n",
            "============================================================\n",
            "  Trying Kaggle API (tuncnguyn/rtts-dataset)...\n",
            "  Kaggle method failed: Could not find kaggle.json. Make sure it's located in /root/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/\n",
            "  Trying UT Austin Box mirror (official RESIDE-beta)...\n",
            "  Downloading: https://utexas.app.box.com/index.php?rm=box_download_shared_file&shared_name=2yekra41udg9rgyzi3ysi513cps621qz&file_id=f_766454923366\n",
            "RTTS: 1.07GB [00:14, 74.6MB/s]                \n",
            "  Saved to: /content/computer_vision_expirement/datasets/rtts/RTTS.zip\n",
            "  Extracting RTTS.zip...\n",
            "  Extracted to: /content/computer_vision_expirement/datasets/rtts\n",
            "  RTTS download complete!\n",
            "  Location: /content/computer_vision_expirement/datasets/rtts\n",
            "\n",
            "============================================================\n",
            "DOWNLOADING: LFW (Labeled Faces in the Wild)\n",
            "============================================================\n",
            "  Trying sklearn.datasets.fetch_lfw_people...\n",
            "  Downloaded via sklearn: 13233 images\n",
            "  LFW download complete!\n",
            "  Location: /content/computer_vision_expirement/datasets/lfw\n",
            "\n",
            "============================================================\n",
            "DOWNLOADING: WiderFace\n",
            "============================================================\n",
            "  Downloading WIDER_train.zip from Google Drive...\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=15hGDLhsx8bLgLcIRD5DhYt5iBxnjNF1M\n",
            "From (redirected): https://drive.google.com/uc?id=15hGDLhsx8bLgLcIRD5DhYt5iBxnjNF1M&confirm=t&uuid=327dee75-29f7-4b9f-85f0-c7f76f46b733\n",
            "To: /content/computer_vision_expirement/datasets/widerface/WIDER_train.zip\n",
            "100% 1.47G/1.47G [00:07<00:00, 206MB/s]\n",
            "  Extracting WIDER_train.zip...\n",
            "  Extracted to: /content/computer_vision_expirement/datasets/widerface\n",
            "  Downloading WIDER_val.zip from Google Drive...\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1GUCogbp16PMGa39thoMMeWxp7Rp5oM8Q\n",
            "From (redirected): https://drive.google.com/uc?id=1GUCogbp16PMGa39thoMMeWxp7Rp5oM8Q&confirm=t&uuid=787e2559-69ca-4b4a-ab83-da1c825bd958\n",
            "To: /content/computer_vision_expirement/datasets/widerface/WIDER_val.zip\n",
            "100% 363M/363M [00:01<00:00, 244MB/s]\n",
            "  Extracting WIDER_val.zip...\n",
            "  Extracted to: /content/computer_vision_expirement/datasets/widerface\n",
            "  Downloading wider_face_split.zip from Hugging Face mirror...\n",
            "  Downloading: https://huggingface.co/datasets/wider_face/resolve/main/data/wider_face_split.zip\n",
            "wider_face_split.zip: 3.60MB [00:00, 11.5MB/s]                \n",
            "  Saved to: /content/computer_vision_expirement/datasets/widerface/wider_face_split.zip\n",
            "  Extracting wider_face_split.zip...\n",
            "  Extracted to: /content/computer_vision_expirement/datasets/widerface\n",
            "  WiderFace download complete!\n",
            "  Location: /content/computer_vision_expirement/datasets/widerface\n",
            "\n",
            "============================================================\n",
            "DOWNLOAD SUMMARY\n",
            "============================================================\n",
            "  rtts         ->   4322 images found\n",
            "  lfw          ->  13233 images found\n",
            "  widerface    ->  16106 images found\n",
            "\n",
            "Done! Next: run preprocess_data.py\n",
            "\n",
            "--- Preprocessing ---\n",
            "Phase 1: Data Preprocessing\n",
            "Target size: (640, 640)\n",
            "Split ratio: {'train': 0.7, 'val': 0.15, 'test': 0.15}\n",
            "Chunk size: 200 images\n",
            "JPEG quality: 90\n",
            "\n",
            "============================================================\n",
            "PREPROCESSING: rtts\n",
            "============================================================\n",
            "  Found 4322 images\n",
            "  Chunk size: 200 images | JPEG quality: 90\n",
            "\n",
            "  train: 3025 images in 16 chunks\n",
            "    train: 100%|███████████████████████████| 3025/3025 [04:54<00:00, 10.26img/s]\n",
            "    -> processed: 3025 | skipped: 0 | failed: 0\n",
            "\n",
            "  val: 648 images in 4 chunks\n",
            "    val: 100%|███████████████████████████████| 648/648 [01:02<00:00, 10.38img/s]\n",
            "    -> processed: 648 | skipped: 0 | failed: 0\n",
            "\n",
            "  test: 649 images in 4 chunks\n",
            "    test: 100%|██████████████████████████████| 649/649 [01:00<00:00, 10.74img/s]\n",
            "    -> processed: 649 | skipped: 0 | failed: 0\n",
            "\n",
            "  ────────────────────────────────────────\n",
            "  rtts DONE\n",
            "    Total processed: 4322\n",
            "    Already existed: 0\n",
            "    Failed/corrupt:  0\n",
            "    train: 3025 images\n",
            "    val: 648 images\n",
            "    test: 649 images\n",
            "  Output: /content/computer_vision_expirement/datasets/rtts_processed\n",
            "\n",
            "============================================================\n",
            "PREPROCESSING: lfw\n",
            "============================================================\n",
            "  Found 13233 images\n",
            "  Chunk size: 200 images | JPEG quality: 90\n",
            "\n",
            "  train: 9263 images in 47 chunks\n",
            "    train: 100%|██████████████████████████| 9263/9263 [00:40<00:00, 229.71img/s]\n",
            "    -> processed: 9263 | skipped: 0 | failed: 0\n",
            "\n",
            "  val: 1984 images in 10 chunks\n",
            "    val: 100%|████████████████████████████| 1984/1984 [00:08<00:00, 239.57img/s]\n",
            "    -> processed: 1984 | skipped: 0 | failed: 0\n",
            "\n",
            "  test: 1986 images in 10 chunks\n",
            "    test: 100%|███████████████████████████| 1986/1986 [00:07<00:00, 278.93img/s]\n",
            "    -> processed: 1986 | skipped: 0 | failed: 0\n",
            "\n",
            "  ────────────────────────────────────────\n",
            "  lfw DONE\n",
            "    Total processed: 13233\n",
            "    Already existed: 0\n",
            "    Failed/corrupt:  0\n",
            "    train: 9263 images\n",
            "    val: 1984 images\n",
            "    test: 1986 images\n",
            "  Output: /content/computer_vision_expirement/datasets/lfw_processed\n",
            "\n",
            "============================================================\n",
            "PREPROCESSING: widerface\n",
            "============================================================\n",
            "  Found 16106 images\n",
            "  Chunk size: 200 images | JPEG quality: 90\n",
            "\n",
            "  train: 11274 images in 57 chunks\n",
            "    train: 100%|████████████████████████| 11274/11274 [01:47<00:00, 104.40img/s]\n",
            "    -> processed: 11274 | skipped: 0 | failed: 0\n",
            "\n",
            "  val: 2415 images in 13 chunks\n",
            "    val: 100%|████████████████████████████| 2415/2415 [00:23<00:00, 100.87img/s]\n",
            "    -> processed: 2415 | skipped: 0 | failed: 0\n",
            "\n",
            "  test: 2417 images in 13 chunks\n",
            "    test: 100%|███████████████████████████| 2417/2417 [00:23<00:00, 103.81img/s]\n",
            "    -> processed: 2417 | skipped: 0 | failed: 0\n",
            "\n",
            "  ────────────────────────────────────────\n",
            "  widerface DONE\n",
            "    Total processed: 16106\n",
            "    Already existed: 0\n",
            "    Failed/corrupt:  0\n",
            "    train: 11274 images\n",
            "    val: 2415 images\n",
            "    test: 2417 images\n",
            "  Output: /content/computer_vision_expirement/datasets/widerface_processed\n",
            "\n",
            "============================================================\n",
            "PREPROCESSING COMPLETE\n",
            "============================================================\n",
            "Next: run augment_data.py\n",
            "\n",
            "Datasets ready at: /content/computer_vision_expirement/datasets\n",
            "Results will be saved to Drive: /content/drive/MyDrive/computer_vision/results/phase2\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "PROJECT_DIR = '/content/drive/MyDrive/computer_vision'\n",
        "RESULTS_DIR = f'{PROJECT_DIR}/results/phase2'\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# Clone repo and download datasets to LOCAL disk (fast SSD, not Drive)\n",
        "%cd /content\n",
        "!rm -rf computer_vision_expirement\n",
        "!git clone https://github.com/Ib-Programmer/computer_vision_expirement.git\n",
        "%cd computer_vision_expirement\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "# Download and preprocess datasets locally\n",
        "print(\"\\n--- Downloading datasets to local disk ---\")\n",
        "!python scripts/download_datasets.py rtts lfw widerface\n",
        "print(\"\\n--- Preprocessing ---\")\n",
        "!python scripts/preprocess_data.py rtts lfw widerface\n",
        "\n",
        "DATASETS_DIR = '/content/computer_vision_expirement/datasets'\n",
        "print(f\"\\nDatasets ready at: {DATASETS_DIR}\")\n",
        "print(f\"Results will be saved to Drive: {RESULTS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rzHCOqIa13N0",
        "outputId": "9cf0dab0-5c19-4ad0-97e1-977c206b3b0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q pyiqa basicsr einops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14KbnWgs13N0"
      },
      "source": [
        "## 2.1 Load Test Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-LXborRV13N1",
        "outputId": "53d37b1c-8466-4ca9-fa26-19380c40592b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 100 test images\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "# Load sample test images from each dataset\n",
        "def load_test_samples(dataset_dir, max_samples=50):\n",
        "    images = []\n",
        "    paths = sorted(glob.glob(f'{dataset_dir}/*_processed/test/*.jpg') +\n",
        "                   glob.glob(f'{dataset_dir}/*_processed/test/*.png'))\n",
        "    for p in paths[:max_samples]:\n",
        "        img = cv2.imread(p)\n",
        "        if img is not None:\n",
        "            images.append((p, img))\n",
        "    return images\n",
        "\n",
        "test_images = load_test_samples(DATASETS_DIR, max_samples=100)\n",
        "print(f\"Loaded {len(test_images)} test images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnD63TSB13N1"
      },
      "source": [
        "## 2.2 Setup Enhancement Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9jFjUJXL13N1",
        "outputId": "3a77c4d6-a1af-4019-f076-fadbcb98c8ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARNING] Zero-DCE++ weights not found in cloned repo\n"
          ]
        }
      ],
      "source": [
        "# Zero-DCE++ for low-light enhancement\n",
        "# Weights are included in the official GitHub repo (no Google Drive needed)\n",
        "!git clone https://github.com/Li-Chongyi/Zero-DCE_extension.git 2>/dev/null || echo \"Zero-DCE++ already cloned\"\n",
        "\n",
        "import os\n",
        "os.makedirs('weights', exist_ok=True)\n",
        "\n",
        "# Copy weights from the cloned repo\n",
        "zero_dce_src = 'Zero-DCE_extension/snapshots_Zero_DCE++/Epoch99.pth'\n",
        "if os.path.exists(zero_dce_src) and not os.path.exists('weights/zero_dce_pp.pth'):\n",
        "    import shutil\n",
        "    shutil.copy(zero_dce_src, 'weights/zero_dce_pp.pth')\n",
        "    print(f\"Zero-DCE++ weights copied from repo: {os.path.getsize('weights/zero_dce_pp.pth') / 1e6:.1f} MB\")\n",
        "elif os.path.exists('weights/zero_dce_pp.pth'):\n",
        "    print(\"Zero-DCE++ weights already available\")\n",
        "else:\n",
        "    print(\"[WARNING] Zero-DCE++ weights not found in cloned repo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5m7yrB-613N1",
        "outputId": "0f8cdc64-09a4-44a1-e223-1f8c09816c94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Restormer deraining weights from Hugging Face...\n",
            "Restormer weights downloaded: 104.7 MB\n"
          ]
        }
      ],
      "source": [
        "# Restormer for general image restoration\n",
        "# Download from Hugging Face (no Google Drive needed)\n",
        "!git clone https://github.com/swz30/Restormer.git 2>/dev/null || echo \"Restormer already cloned\"\n",
        "\n",
        "if not os.path.exists('weights/restormer_deraining.pth'):\n",
        "    print(\"Downloading Restormer deraining weights from Hugging Face...\")\n",
        "    !wget -q -O weights/restormer_deraining.pth \"https://huggingface.co/deepinv/Restormer/resolve/main/deraining.pth\"\n",
        "    if os.path.exists('weights/restormer_deraining.pth'):\n",
        "        print(f\"Restormer weights downloaded: {os.path.getsize('weights/restormer_deraining.pth') / 1e6:.1f} MB\")\n",
        "    else:\n",
        "        print(\"[WARNING] Restormer weights download failed\")\n",
        "else:\n",
        "    print(\"Restormer weights already available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eDEae0jt13N1",
        "outputId": "d4ac42de-c54d-4846-91cd-85d2a58b2b0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading FFA-Net weights from Kaggle...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/cli.py\", line 68, in main\n",
            "    out = args.func(**command_args)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n",
            "    with self.build_kaggle_client() as kaggle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
            "    username=self.config_values['username'],\n",
            "             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'username'\n",
            "[WARNING] FFA-Net weights not found in Kaggle download\n",
            "Trying wget from GitHub release...\n",
            "GitHub release not available\n",
            "\n",
            "========================================\n",
            "Model Weights Status:\n",
            "  Zero-DCE++: MISSING\n",
            "  Restormer: OK (104.7 MB)\n",
            "  FFA-Net: OK (0.0 MB)\n"
          ]
        }
      ],
      "source": [
        "# FFA-Net for dehazing\n",
        "# Download from Kaggle (no Google Drive needed)\n",
        "!git clone https://github.com/zhilin007/FFA-Net.git 2>/dev/null || echo \"FFA-Net already cloned\"\n",
        "\n",
        "if not os.path.exists('weights/ffa_net.pk'):\n",
        "    print(\"Downloading FFA-Net weights from Kaggle...\")\n",
        "    try:\n",
        "        !pip install -q kaggle\n",
        "        !kaggle datasets download -d balraj98/ffanet-pretrained-weights -p weights/ --unzip -q\n",
        "        # Kaggle dataset may have a different filename, find and rename\n",
        "        import glob\n",
        "        ffa_files = glob.glob('weights/*.pk') + glob.glob('weights/**/*.pk', recursive=True)\n",
        "        if ffa_files:\n",
        "            import shutil\n",
        "            shutil.copy(ffa_files[0], 'weights/ffa_net.pk')\n",
        "            print(f\"FFA-Net weights downloaded: {os.path.getsize('weights/ffa_net.pk') / 1e6:.1f} MB\")\n",
        "        else:\n",
        "            print(\"[WARNING] FFA-Net weights not found in Kaggle download\")\n",
        "            print(\"Trying wget from GitHub release...\")\n",
        "            !wget -q -O weights/ffa_net.pk \"https://github.com/zhilin007/FFA-Net/releases/download/v1.0/ffa_net.pk\" 2>/dev/null || echo \"GitHub release not available\"\n",
        "    except Exception as e:\n",
        "        print(f\"Kaggle download failed: {e}\")\n",
        "        print(\"Manual download: https://www.kaggle.com/datasets/balraj98/ffanet-pretrained-weights\")\n",
        "else:\n",
        "    print(\"FFA-Net weights already available\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"Model Weights Status:\")\n",
        "for name, path in [(\"Zero-DCE++\", \"weights/zero_dce_pp.pth\"),\n",
        "                    (\"Restormer\", \"weights/restormer_deraining.pth\"),\n",
        "                    (\"FFA-Net\", \"weights/ffa_net.pk\")]:\n",
        "    if os.path.exists(path):\n",
        "        size = os.path.getsize(path) / 1e6\n",
        "        print(f\"  {name}: OK ({size:.1f} MB)\")\n",
        "    else:\n",
        "        print(f\"  {name}: MISSING\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n68apxq13N2"
      },
      "source": [
        "## 2.3 Run Enhancement & Measure Quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xhykortG13N2",
        "outputId": "0b6f8671-9d44-4770-c5df-88e7b60b0f25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://huggingface.co/chaofengc/IQA-PyTorch-Weights/resolve/main/niqe_modelparameters.mat\" to /root/.cache/torch/hub/pyiqa/niqe_modelparameters.mat\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8.15k/8.15k [00:00<00:00, 25.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "import pyiqa\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Initialize no-reference metrics\n",
        "niqe_metric = pyiqa.create_metric('niqe', device='cuda' if __import__('torch').cuda.is_available() else 'cpu')\n",
        "\n",
        "def evaluate_image_quality(original, enhanced):\n",
        "    \"\"\"Calculate quality metrics between original and enhanced images.\"\"\"\n",
        "    # Convert to float\n",
        "    orig_f = original.astype(np.float64) / 255.0\n",
        "    enh_f = enhanced.astype(np.float64) / 255.0\n",
        "\n",
        "    metrics = {}\n",
        "    metrics['psnr'] = psnr(orig_f, enh_f, data_range=1.0)\n",
        "    metrics['ssim'] = ssim(orig_f, enh_f, data_range=1.0, channel_axis=2)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def measure_inference_time(model_fn, image, n_runs=10):\n",
        "    \"\"\"Measure average inference time.\"\"\"\n",
        "    times = []\n",
        "    for _ in range(n_runs):\n",
        "        start = time.time()\n",
        "        _ = model_fn(image)\n",
        "        times.append(time.time() - start)\n",
        "    return np.mean(times) * 1000  # ms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_a3ZdsZV13N2",
        "outputId": "f99febc4-b653-4deb-e497-fee940553b0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running enhancement evaluation...\n",
            "This may take 10-30 minutes depending on GPU...\n",
            "\n",
            "Evaluation framework ready.\n",
            "Run each model section below to populate results.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "results = []\n",
        "\n",
        "# Process each test image through each model\n",
        "# Note: Actual model loading/inference code depends on model availability\n",
        "# This is the evaluation framework - adjust model paths as needed\n",
        "\n",
        "print(\"Running enhancement evaluation...\")\n",
        "print(\"This may take 10-30 minutes depending on GPU...\")\n",
        "\n",
        "# Placeholder for model inference functions\n",
        "# Each model's inference will be added when weights are confirmed available\n",
        "\n",
        "# For now, create the evaluation framework\n",
        "evaluation_df = pd.DataFrame(columns=['Model', 'Avg_PSNR', 'Avg_SSIM', 'Avg_NIQE', 'Avg_Latency_ms'])\n",
        "print(\"\\nEvaluation framework ready.\")\n",
        "print(\"Run each model section below to populate results.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCCGaDe213N2"
      },
      "source": [
        "## 2.4 Results Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eytgc1D-13N3",
        "outputId": "f36c526b-4dfc-4c7c-e8bd-aac914bf3eee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualization functions ready.\n",
            "Results will be saved to: /content/drive/MyDrive/computer_vision/results/phase2\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create comparison visualization\n",
        "def show_enhancement_comparison(original, enhanced_dict, title=\"Enhancement Comparison\"):\n",
        "    n = 1 + len(enhanced_dict)\n",
        "    fig, axes = plt.subplots(1, n, figsize=(4*n, 4))\n",
        "\n",
        "    axes[0].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
        "    axes[0].set_title('Original')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    for i, (name, img) in enumerate(enhanced_dict.items(), 1):\n",
        "        axes[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        axes[i].set_title(name)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{RESULTS_DIR}/enhancement_comparison.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "print(\"Visualization functions ready.\")\n",
        "print(\"Results will be saved to:\", RESULTS_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eTvGRR1R13N3",
        "outputId": "f8690341-5f76-4a70-922a-743f263559ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Phase 2 results saved to: /content/drive/MyDrive/computer_vision/results/phase2\n",
            "Next: Open Phase3_Object_Detection.ipynb\n"
          ]
        }
      ],
      "source": [
        "# Save evaluation results\n",
        "# evaluation_df.to_csv(f'{RESULTS_DIR}/enhancement_benchmark.csv', index=False)\n",
        "print(f\"\\nPhase 2 results saved to: {RESULTS_DIR}\")\n",
        "print(\"Next: Open Phase3_Object_Detection.ipynb\")"
      ]
    }
  ]
}