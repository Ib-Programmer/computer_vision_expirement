{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Image Enhancement Evaluation\n",
    "Evaluating Restormer, FFA-Net, and Zero-DCE++ on degraded outdoor images.\n",
    "\n",
    "**Metrics**: PSNR, SSIM, NIQE, Inference Latency\n",
    "**Goal**: Select the best enhancement model for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import drive\ndrive.mount('/content/drive')\n\nimport os\nPROJECT_DIR = '/content/drive/MyDrive/computer_vision'\nRESULTS_DIR = f'{PROJECT_DIR}/results/phase2'\nos.makedirs(RESULTS_DIR, exist_ok=True)\n\n# Clone repo and download datasets to LOCAL disk (fast SSD, not Drive)\n%cd /content\n!rm -rf computer_vision_expirement\n!git clone https://github.com/Ib-Programmer/computer_vision_expirement.git\n%cd computer_vision_expirement\n!pip install -q -r requirements.txt\n\n# Download and preprocess datasets locally\nprint(\"\\n--- Downloading datasets to local disk ---\")\n!python scripts/download_datasets.py rtts lfw widerface\nprint(\"\\n--- Preprocessing ---\")\n!python scripts/preprocess_data.py rtts lfw widerface\n\nDATASETS_DIR = '/content/computer_vision_expirement/datasets'\nprint(f\"\\nDatasets ready at: {DATASETS_DIR}\")\nprint(f\"Results will be saved to Drive: {RESULTS_DIR}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pyiqa basicsr einops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Load sample test images from each dataset\n",
    "def load_test_samples(dataset_dir, max_samples=50):\n",
    "    images = []\n",
    "    paths = sorted(glob.glob(f'{dataset_dir}/*_processed/test/*.jpg') + \n",
    "                   glob.glob(f'{dataset_dir}/*_processed/test/*.png'))\n",
    "    for p in paths[:max_samples]:\n",
    "        img = cv2.imread(p)\n",
    "        if img is not None:\n",
    "            images.append((p, img))\n",
    "    return images\n",
    "\n",
    "test_images = load_test_samples(DATASETS_DIR, max_samples=100)\n",
    "print(f\"Loaded {len(test_images)} test images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Setup Enhancement Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Zero-DCE++ for low-light enhancement\n# Weights are included in the official GitHub repo (no Google Drive needed)\n!git clone https://github.com/Li-Chongyi/Zero-DCE_extension.git 2>/dev/null || echo \"Zero-DCE++ already cloned\"\n\nimport os\nos.makedirs('weights', exist_ok=True)\n\n# Copy weights from the cloned repo\nzero_dce_src = 'Zero-DCE_extension/snapshots_Zero_DCE++/Epoch99.pth'\nif os.path.exists(zero_dce_src) and not os.path.exists('weights/zero_dce_pp.pth'):\n    import shutil\n    shutil.copy(zero_dce_src, 'weights/zero_dce_pp.pth')\n    print(f\"Zero-DCE++ weights copied from repo: {os.path.getsize('weights/zero_dce_pp.pth') / 1e6:.1f} MB\")\nelif os.path.exists('weights/zero_dce_pp.pth'):\n    print(\"Zero-DCE++ weights already available\")\nelse:\n    print(\"[WARNING] Zero-DCE++ weights not found in cloned repo\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Restormer for general image restoration\n# Download from Hugging Face (no Google Drive needed)\n!git clone https://github.com/swz30/Restormer.git 2>/dev/null || echo \"Restormer already cloned\"\n\nif not os.path.exists('weights/restormer_deraining.pth'):\n    print(\"Downloading Restormer deraining weights from Hugging Face...\")\n    !wget -q -O weights/restormer_deraining.pth \"https://huggingface.co/deepinv/Restormer/resolve/main/deraining.pth\"\n    if os.path.exists('weights/restormer_deraining.pth'):\n        print(f\"Restormer weights downloaded: {os.path.getsize('weights/restormer_deraining.pth') / 1e6:.1f} MB\")\n    else:\n        print(\"[WARNING] Restormer weights download failed\")\nelse:\n    print(\"Restormer weights already available\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# FFA-Net for dehazing\n# Download from Kaggle (no Google Drive needed)\n!git clone https://github.com/zhilin007/FFA-Net.git 2>/dev/null || echo \"FFA-Net already cloned\"\n\nif not os.path.exists('weights/ffa_net.pk'):\n    print(\"Downloading FFA-Net weights from Kaggle...\")\n    try:\n        !pip install -q kaggle\n        !kaggle datasets download -d balraj98/ffanet-pretrained-weights -p weights/ --unzip -q\n        # Kaggle dataset may have a different filename, find and rename\n        import glob\n        ffa_files = glob.glob('weights/*.pk') + glob.glob('weights/**/*.pk', recursive=True)\n        if ffa_files:\n            import shutil\n            shutil.copy(ffa_files[0], 'weights/ffa_net.pk')\n            print(f\"FFA-Net weights downloaded: {os.path.getsize('weights/ffa_net.pk') / 1e6:.1f} MB\")\n        else:\n            print(\"[WARNING] FFA-Net weights not found in Kaggle download\")\n            print(\"Trying wget from GitHub release...\")\n            !wget -q -O weights/ffa_net.pk \"https://github.com/zhilin007/FFA-Net/releases/download/v1.0/ffa_net.pk\" 2>/dev/null || echo \"GitHub release not available\"\n    except Exception as e:\n        print(f\"Kaggle download failed: {e}\")\n        print(\"Manual download: https://www.kaggle.com/datasets/balraj98/ffanet-pretrained-weights\")\nelse:\n    print(\"FFA-Net weights already available\")\n\n# Summary\nprint(\"\\n\" + \"=\" * 40)\nprint(\"Model Weights Status:\")\nfor name, path in [(\"Zero-DCE++\", \"weights/zero_dce_pp.pth\"),\n                    (\"Restormer\", \"weights/restormer_deraining.pth\"),\n                    (\"FFA-Net\", \"weights/ffa_net.pk\")]:\n    if os.path.exists(path):\n        size = os.path.getsize(path) / 1e6\n        print(f\"  {name}: OK ({size:.1f} MB)\")\n    else:\n        print(f\"  {name}: MISSING\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Run Enhancement & Measure Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyiqa\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Initialize no-reference metrics\n",
    "niqe_metric = pyiqa.create_metric('niqe', device='cuda' if __import__('torch').cuda.is_available() else 'cpu')\n",
    "\n",
    "def evaluate_image_quality(original, enhanced):\n",
    "    \"\"\"Calculate quality metrics between original and enhanced images.\"\"\"\n",
    "    # Convert to float\n",
    "    orig_f = original.astype(np.float64) / 255.0\n",
    "    enh_f = enhanced.astype(np.float64) / 255.0\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['psnr'] = psnr(orig_f, enh_f, data_range=1.0)\n",
    "    metrics['ssim'] = ssim(orig_f, enh_f, data_range=1.0, channel_axis=2)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def measure_inference_time(model_fn, image, n_runs=10):\n",
    "    \"\"\"Measure average inference time.\"\"\"\n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        start = time.time()\n",
    "        _ = model_fn(image)\n",
    "        times.append(time.time() - start)\n",
    "    return np.mean(times) * 1000  # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "# Process each test image through each model\n",
    "# Note: Actual model loading/inference code depends on model availability\n",
    "# This is the evaluation framework - adjust model paths as needed\n",
    "\n",
    "print(\"Running enhancement evaluation...\")\n",
    "print(\"This may take 10-30 minutes depending on GPU...\")\n",
    "\n",
    "# Placeholder for model inference functions\n",
    "# Each model's inference will be added when weights are confirmed available\n",
    "\n",
    "# For now, create the evaluation framework\n",
    "evaluation_df = pd.DataFrame(columns=['Model', 'Avg_PSNR', 'Avg_SSIM', 'Avg_NIQE', 'Avg_Latency_ms'])\n",
    "print(\"\\nEvaluation framework ready.\")\n",
    "print(\"Run each model section below to populate results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create comparison visualization\n",
    "def show_enhancement_comparison(original, enhanced_dict, title=\"Enhancement Comparison\"):\n",
    "    n = 1 + len(enhanced_dict)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(4*n, 4))\n",
    "    \n",
    "    axes[0].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    for i, (name, img) in enumerate(enhanced_dict.items(), 1):\n",
    "        axes[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axes[i].set_title(name)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{RESULTS_DIR}/enhancement_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualization functions ready.\")\n",
    "print(\"Results will be saved to:\", RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation results\n",
    "# evaluation_df.to_csv(f'{RESULTS_DIR}/enhancement_benchmark.csv', index=False)\n",
    "print(f\"\\nPhase 2 results saved to: {RESULTS_DIR}\")\n",
    "print(\"Next: Open Phase3_Object_Detection.ipynb\")"
   ]
  }
 ]
}