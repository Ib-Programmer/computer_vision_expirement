{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Object Detection Performance Evaluation\n",
    "Training and comparing YOLOv8 and RT-DETR on BDD100K with outdoor augmentations.\n",
    "\n",
    "**Metrics**: mAP@0.5, mAP@0.5:0.95, Precision, Recall, FPS\n",
    "**Goal**: Determine best detection model and impact of outdoor augmentation\n",
    "\n",
    "**IMPORTANT**: Set Runtime > Change runtime type > **GPU** (T4) before running!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "PROJECT_DIR = '/content/drive/MyDrive/computer_vision'\n",
    "RESULTS_DIR = f'{PROJECT_DIR}/results/phase3'\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Clone repo and download datasets to LOCAL disk (fast SSD, not Drive)\n",
    "%cd /content\n",
    "!rm -rf computer_vision_expirement\n",
    "!git clone https://github.com/Ib-Programmer/computer_vision_expirement.git\n",
    "%cd computer_vision_expirement\n",
    "!pip install -q ultralytics albumentations pyyaml\n",
    "\n",
    "# Download BDD100K (images + labels) and convert labels to YOLO format\n",
    "print('\\n--- Downloading BDD100K to local disk ---')\n",
    "!python scripts/download_datasets.py bdd100k\n",
    "print('\\n--- Converting BDD100K labels to YOLO format ---')\n",
    "!python scripts/preprocess_data.py bdd100k\n",
    "\n",
    "DATASETS_DIR = '/content/computer_vision_expirement/datasets'\n",
    "print(f'\\nDatasets ready at: {DATASETS_DIR}')\n",
    "print(f'Results will be saved to Drive: {RESULTS_DIR}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Verify GPU & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import torch\nimport glob\n\n# GPU check — set DEVICE for all training cells\nprint('=' * 60)\nprint('ENVIRONMENT CHECK')\nprint('=' * 60)\nif torch.cuda.is_available():\n    DEVICE = 0  # GPU index\n    print(f'GPU: {torch.cuda.get_device_name(0)}')\n    print(f'VRAM: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB')\n    print('Training will use GPU (~1-2 hours for 50 epochs)')\nelse:\n    DEVICE = 'cpu'\n    print('WARNING: No GPU detected!')\n    print('Go to Runtime > Change runtime type > T4 GPU')\n    print('Training on CPU is possible but VERY slow (~40+ hours).')\n    print('If your GPU quota is exhausted, try again tomorrow or use Colab Pro.')\n\nprint(f'\\nDEVICE = {DEVICE}')\n\n# Verify BDD100K YOLO dataset\nyolo_dir = f'{DATASETS_DIR}/bdd100k_yolo'\nprint(f'\\nDataset directory: {yolo_dir}')\n\nfor split in ['train', 'val']:\n    img_dir = f'{yolo_dir}/{split}/images'\n    lbl_dir = f'{yolo_dir}/{split}/labels'\n    if os.path.exists(img_dir) and os.path.exists(lbl_dir):\n        n_imgs = len(glob.glob(f'{img_dir}/*.jpg'))\n        n_lbls = len(glob.glob(f'{lbl_dir}/*.txt'))\n        non_empty = sum(1 for f in glob.glob(f'{lbl_dir}/*.txt') if os.path.getsize(f) > 0)\n        print(f'  {split}: {n_imgs} images, {n_lbls} labels ({non_empty} with objects)')\n    else:\n        print(f'  {split}: MISSING! Re-run the setup cell above.')\n\n# Show sample label to confirm format is correct\nsample_labels = glob.glob(f'{yolo_dir}/train/labels/*.txt')[:5]\nfor lbl_path in sample_labels:\n    with open(lbl_path) as f:\n        content = f.read().strip()\n    if content:\n        print(f'\\nSample label ({os.path.basename(lbl_path)}):')\n        for line in content.split('\\n')[:3]:\n            print(f'  {line}')\n        break",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Prepare Dataset Config"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import yaml\n",
    "\n",
    "# Create dataset.yaml pointing to YOLO-formatted BDD100K\n",
    "dataset_config = {\n",
    "    'path': f'{DATASETS_DIR}/bdd100k_yolo',\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'names': {\n",
    "        0: 'pedestrian',\n",
    "        1: 'rider',\n",
    "        2: 'car',\n",
    "        3: 'truck',\n",
    "        4: 'bus',\n",
    "        5: 'train',\n",
    "        6: 'motorcycle',\n",
    "        7: 'bicycle',\n",
    "        8: 'traffic light',\n",
    "        9: 'traffic sign'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('dataset.yaml', 'w') as f:\n",
    "    yaml.dump(dataset_config, f, default_flow_style=False)\n",
    "\n",
    "print('dataset.yaml created:')\n",
    "with open('dataset.yaml') as f:\n",
    "    print(f.read())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Apply Outdoor Augmentation Patch\n",
    "Patches Ultralytics' built-in Albumentations class to add outdoor-specific degradations:\n",
    "- **Fog** (30% chance)\n",
    "- **Rain** (30% chance)\n",
    "- **Motion blur** (30% chance)\n",
    "- **Low-light** (30% chance)\n",
    "- **Combined effects** (15% chance: fog+blur or rain+dark)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import albumentations as A\n",
    "from ultralytics.data.augment import Albumentations\n",
    "\n",
    "# Save original __init__ so we can restore it for baseline training\n",
    "_original_alb_init = Albumentations.__init__\n",
    "\n",
    "def _outdoor_init(self, p=1.0):\n",
    "    \"\"\"Patch Albumentations with outdoor-specific augmentations.\"\"\"\n",
    "    self.p = p\n",
    "    T = [\n",
    "        # Ultralytics defaults (light)\n",
    "        A.Blur(blur_limit=3, p=0.01),\n",
    "        A.CLAHE(p=0.01),\n",
    "        # Outdoor degradations (30% each)\n",
    "        A.RandomFog(fog_coef_lower=0.2, fog_coef_upper=0.6, alpha_coef=0.08, p=0.3),\n",
    "        A.RandomRain(slant_lower=-10, slant_upper=10, drop_length=20, drop_width=1,\n",
    "                     drop_color=(200, 200, 200), blur_value=3, brightness_coefficient=0.7, p=0.3),\n",
    "        A.MotionBlur(blur_limit=(7, 15), p=0.3),\n",
    "        A.RandomBrightnessContrast(brightness_limit=(-0.5, -0.1), contrast_limit=(-0.3, 0.0), p=0.3),\n",
    "        # Combined effects (15%)\n",
    "        A.OneOf([\n",
    "            A.Compose([A.RandomFog(fog_coef_lower=0.2, fog_coef_upper=0.5, p=1.0),\n",
    "                       A.MotionBlur(blur_limit=(5, 11), p=1.0)]),\n",
    "            A.Compose([A.RandomRain(slant_lower=-10, slant_upper=10, p=1.0),\n",
    "                       A.RandomBrightnessContrast(brightness_limit=(-0.4, -0.1), p=1.0)]),\n",
    "        ], p=0.15),\n",
    "    ]\n",
    "    self.transform = A.Compose(T, bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "    print(f'Outdoor augmentations: fog/rain/blur/dark(30%) + combined(15%)')\n",
    "\n",
    "# Apply outdoor augmentation patch\n",
    "Albumentations.__init__ = _outdoor_init\n",
    "print('Outdoor augmentation patch applied to Ultralytics!')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Train YOLOv8n (Outdoor Augmented)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from ultralytics import YOLO\n\nprint('=' * 60)\nprint(f'Training YOLOv8n WITH outdoor augmentations (device={DEVICE})')\nprint('=' * 60)\n\nmodel_aug = YOLO('yolov8n.pt')\nresults_aug = model_aug.train(\n    data='dataset.yaml',\n    epochs=50,\n    imgsz=640,\n    batch=16,\n    device=DEVICE,\n    project=RESULTS_DIR,\n    name='yolov8n_outdoor_aug',\n    patience=10,\n    save=True,\n    plots=True\n)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Train YOLOv8n (Baseline - No Outdoor Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Restore default Albumentations (no outdoor effects) for fair baseline\nimport importlib\nimport ultralytics.data.augment\nimportlib.reload(ultralytics.data.augment)\nfrom ultralytics.data.augment import Albumentations\n\nprint('=' * 60)\nprint(f'Training YOLOv8n WITHOUT outdoor augmentations (device={DEVICE})')\nprint('=' * 60)\n\nmodel_base = YOLO('yolov8n.pt')\nresults_base = model_base.train(\n    data='dataset.yaml',\n    epochs=50,\n    imgsz=640,\n    batch=16,\n    device=DEVICE,\n    project=RESULTS_DIR,\n    name='yolov8n_baseline',\n    patience=10,\n    save=True,\n    plots=True\n)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Train RT-DETR (Outdoor Augmented)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Re-apply outdoor augmentation patch for RT-DETR\nfrom ultralytics.data.augment import Albumentations\nAlbumentations.__init__ = _outdoor_init\n\nprint('=' * 60)\nprint(f'Training RT-DETR WITH outdoor augmentations (device={DEVICE})')\nprint('=' * 60)\n\nmodel_rtdetr = YOLO('rtdetr-l.pt')\nresults_rtdetr = model_rtdetr.train(\n    data='dataset.yaml',\n    epochs=50,\n    imgsz=640,\n    batch=8,\n    device=DEVICE,\n    project=RESULTS_DIR,\n    name='rtdetr_outdoor_aug',\n    patience=10,\n    save=True,\n    plots=True\n)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Evaluate All Models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "models = {\n",
    "    'YOLOv8n_outdoor_aug': f'{RESULTS_DIR}/yolov8n_outdoor_aug/weights/best.pt',\n",
    "    'YOLOv8n_baseline': f'{RESULTS_DIR}/yolov8n_baseline/weights/best.pt',\n",
    "    'RT-DETR_outdoor_aug': f'{RESULTS_DIR}/rtdetr_outdoor_aug/weights/best.pt',\n",
    "}\n",
    "\n",
    "results_table = []\n",
    "\n",
    "for name, weights_path in models.items():\n",
    "    if not os.path.exists(weights_path):\n",
    "        print(f'[SKIP] {name}: weights not found')\n",
    "        continue\n",
    "\n",
    "    print(f'\\nValidating: {name}')\n",
    "    model = YOLO(weights_path)\n",
    "    val_results = model.val(data='dataset.yaml')\n",
    "\n",
    "    # Measure inference speed\n",
    "    dummy_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)\n",
    "    for _ in range(5):  # warmup\n",
    "        model(dummy_img, verbose=False)\n",
    "    times = []\n",
    "    for _ in range(30):\n",
    "        t0 = time.time()\n",
    "        model(dummy_img, verbose=False)\n",
    "        times.append((time.time() - t0) * 1000)\n",
    "\n",
    "    results_table.append({\n",
    "        'Model': name,\n",
    "        'mAP@0.5': round(val_results.box.map50, 4),\n",
    "        'mAP@0.5:0.95': round(val_results.box.map, 4),\n",
    "        'Precision': round(val_results.box.mp, 4),\n",
    "        'Recall': round(val_results.box.mr, 4),\n",
    "        'Latency_ms': round(np.mean(times), 1),\n",
    "        'FPS': round(1000 / np.mean(times), 1),\n",
    "    })\n",
    "\n",
    "if results_table:\n",
    "    df = pd.DataFrame(results_table)\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('DETECTION RESULTS: Baseline vs Outdoor Augmented')\n",
    "    print('=' * 60)\n",
    "    print(df.to_string(index=False))\n",
    "    df.to_csv(f'{RESULTS_DIR}/detection_comparison.csv', index=False)\n",
    "    print(f'\\nSaved to: {RESULTS_DIR}/detection_comparison.csv')\n",
    "else:\n",
    "    print('No models to evaluate. Train the models first.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Visual Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Use best outdoor-augmented model\n",
    "best_path = f'{RESULTS_DIR}/yolov8n_outdoor_aug/weights/best.pt'\n",
    "if not os.path.exists(best_path):\n",
    "    best_path = f'{RESULTS_DIR}/yolov8n_baseline/weights/best.pt'\n",
    "\n",
    "if os.path.exists(best_path):\n",
    "    model = YOLO(best_path)\n",
    "\n",
    "    # Get sample images from BDD100K val set\n",
    "    test_imgs = glob.glob(f'{DATASETS_DIR}/bdd100k_yolo/val/images/*.jpg')[:6]\n",
    "\n",
    "    if test_imgs:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        for idx, img_path in enumerate(test_imgs):\n",
    "            results = model(img_path, verbose=False)\n",
    "            annotated = results[0].plot()\n",
    "            ax = axes[idx // 3][idx % 3]\n",
    "            ax.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
    "            ax.set_title(os.path.basename(img_path), fontsize=9)\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.suptitle('YOLOv8 Detection Results (Outdoor Augmented)', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{RESULTS_DIR}/detection_samples.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No test images found.')\n",
    "else:\n",
    "    print('Train the models first to see results.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3.9 Cross-Condition Robustness Evaluation\nTest the best model's detection performance under simulated adverse outdoor conditions.\nThis validates whether outdoor augmentation during training improves robustness.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import albumentations as A\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport glob\nimport time\n\n# Define outdoor degradation conditions\nconditions = {\n    'Clean (original)': None,\n    'Fog (heavy)': A.Compose([A.RandomFog(fog_coef_lower=0.4, fog_coef_upper=0.8, alpha_coef=0.08, p=1.0)]),\n    'Rain (heavy)': A.Compose([A.RandomRain(slant_lower=-10, slant_upper=10, drop_length=20, drop_width=1,\n                                             drop_color=(200, 200, 200), blur_value=5, brightness_coefficient=0.6, p=1.0)]),\n    'Low-light': A.Compose([A.RandomBrightnessContrast(brightness_limit=(-0.6, -0.3), contrast_limit=(-0.3, 0.0), p=1.0)]),\n    'Motion blur': A.Compose([A.MotionBlur(blur_limit=(11, 21), p=1.0)]),\n    'Fog + Dark': A.Compose([A.RandomFog(fog_coef_lower=0.3, fog_coef_upper=0.6, p=1.0),\n                              A.RandomBrightnessContrast(brightness_limit=(-0.4, -0.1), p=1.0)]),\n}\n\n# Evaluate both augmented and baseline models under each condition\nmodel_paths = {\n    'YOLOv8n_outdoor_aug': f'{RESULTS_DIR}/yolov8n_outdoor_aug/weights/best.pt',\n    'YOLOv8n_baseline': f'{RESULTS_DIR}/yolov8n_baseline/weights/best.pt',\n}\n\nval_images = sorted(glob.glob(f'{DATASETS_DIR}/bdd100k_yolo/val/images/*.jpg'))[:100]\nprint(f'Evaluating {len(val_images)} images under {len(conditions)} conditions...\\n')\n\ncross_results = []\n\nfor model_name, model_path in model_paths.items():\n    if not os.path.exists(model_path):\n        print(f'[SKIP] {model_name}: weights not found')\n        continue\n    \n    model = YOLO(model_path)\n    \n    for cond_name, transform in conditions.items():\n        detections = 0\n        total_conf = 0\n        n_images = 0\n        \n        for img_path in val_images:\n            img = cv2.imread(img_path)\n            if img is None:\n                continue\n            \n            # Apply degradation\n            if transform is not None:\n                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                img_aug = transform(image=img_rgb)['image']\n                img = cv2.cvtColor(img_aug, cv2.COLOR_RGB2BGR)\n            \n            results = model(img, verbose=False, conf=0.25)\n            n_boxes = len(results[0].boxes)\n            detections += n_boxes\n            if n_boxes > 0:\n                total_conf += results[0].boxes.conf.mean().item()\n            n_images += 1\n        \n        avg_det = detections / max(n_images, 1)\n        avg_conf = total_conf / max(n_images, 1)\n        \n        cross_results.append({\n            'Model': model_name,\n            'Condition': cond_name,\n            'Avg_Detections': round(avg_det, 2),\n            'Avg_Confidence': round(avg_conf, 4),\n            'Total_Objects': detections,\n        })\n        print(f'  {model_name} | {cond_name}: {avg_det:.1f} det/img, conf={avg_conf:.3f}')\n\nif cross_results:\n    cross_df = pd.DataFrame(cross_results)\n    print('\\n' + '=' * 70)\n    print('CROSS-CONDITION ROBUSTNESS RESULTS')\n    print('=' * 70)\n    print(cross_df.to_string(index=False))\n    cross_df.to_csv(f'{RESULTS_DIR}/cross_condition_robustness.csv', index=False)\n    print(f'\\nSaved to: {RESULTS_DIR}/cross_condition_robustness.csv')\n    \n    # Show improvement from outdoor augmentation\n    print('\\n--- Augmentation Benefit Analysis ---')\n    for cond in conditions:\n        aug_row = [r for r in cross_results if r['Model'] == 'YOLOv8n_outdoor_aug' and r['Condition'] == cond]\n        base_row = [r for r in cross_results if r['Model'] == 'YOLOv8n_baseline' and r['Condition'] == cond]\n        if aug_row and base_row:\n            delta = aug_row[0]['Avg_Detections'] - base_row[0]['Avg_Detections']\n            print(f'  {cond}: augmented has {delta:+.1f} more det/img')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3.10 Literature Comparison (Published Benchmarks)\nComparing our results with published detection benchmarks from peer-reviewed papers.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\n\n# Published benchmarks: COCO val2017\ncoco_literature = pd.DataFrame([\n    {'Method': 'Faster R-CNN (Ren et al., 2015)', 'Backbone': 'ResNet-101-FPN', 'mAP@0.5': 59.1, 'mAP@0.5:0.95': 36.2, 'FPS': 5.0, 'Source': 'NeurIPS 2015'},\n    {'Method': 'SSD300 (Liu et al., 2016)', 'Backbone': 'VGG-16', 'mAP@0.5': 43.1, 'mAP@0.5:0.95': 25.1, 'FPS': 46.0, 'Source': 'ECCV 2016'},\n    {'Method': 'SSD512 (Liu et al., 2016)', 'Backbone': 'VGG-16', 'mAP@0.5': 48.5, 'mAP@0.5:0.95': 28.8, 'FPS': 19.0, 'Source': 'ECCV 2016'},\n    {'Method': 'RetinaNet (Lin et al., 2017)', 'Backbone': 'ResNet-101-FPN', 'mAP@0.5': 57.5, 'mAP@0.5:0.95': 37.8, 'FPS': 11.0, 'Source': 'ICCV 2017'},\n    {'Method': 'DETR (Carion et al., 2020)', 'Backbone': 'ResNet-50', 'mAP@0.5': 58.9, 'mAP@0.5:0.95': 42.0, 'FPS': 28.0, 'Source': 'ECCV 2020'},\n    {'Method': 'Deformable DETR (Zhu et al., 2021)', 'Backbone': 'ResNet-50', 'mAP@0.5': 62.3, 'mAP@0.5:0.95': 43.8, 'FPS': 19.0, 'Source': 'ICLR 2021'},\n    {'Method': 'YOLOv8n (Jocher et al., 2023)', 'Backbone': 'CSPDarknet', 'mAP@0.5': 52.6, 'mAP@0.5:0.95': 37.3, 'FPS': 400.0, 'Source': 'Ultralytics 2023'},\n    {'Method': 'YOLOv8s (Jocher et al., 2023)', 'Backbone': 'CSPDarknet', 'mAP@0.5': 57.6, 'mAP@0.5:0.95': 44.9, 'FPS': 280.0, 'Source': 'Ultralytics 2023'},\n    {'Method': 'YOLOv8l (Jocher et al., 2023)', 'Backbone': 'CSPDarknet', 'mAP@0.5': 62.6, 'mAP@0.5:0.95': 52.9, 'FPS': 120.0, 'Source': 'Ultralytics 2023'},\n    {'Method': 'RT-DETR-L (Lv et al., 2023)', 'Backbone': 'ResNet-50/HGNetv2', 'mAP@0.5': 72.8, 'mAP@0.5:0.95': 53.0, 'FPS': 114.0, 'Source': 'arXiv 2023'},\n])\n\n# Published benchmarks: BDD100K val\nbdd_literature = pd.DataFrame([\n    {'Method': 'Faster R-CNN', 'mAP@0.5': 30.0, 'Source': 'BDD100K paper (Yu et al., 2020)'},\n    {'Method': 'Cascade R-CNN', 'mAP@0.5': 32.5, 'Source': 'BDD100K paper'},\n    {'Method': 'YOLOv5s', 'mAP@0.5': 38.9, 'Source': 'Community benchmark'},\n    {'Method': 'YOLOv8n', 'mAP@0.5': 40.2, 'Source': 'Community benchmark'},\n    {'Method': 'YOLOv8l', 'mAP@0.5': 48.3, 'Source': 'Community benchmark'},\n    {'Method': 'RT-DETR-L', 'mAP@0.5': 46.5, 'Source': 'Community benchmark'},\n])\n\nprint('=' * 80)\nprint('TABLE 3.1: Object Detection — Published Benchmarks (COCO val2017)')\nprint('=' * 80)\nprint(coco_literature.to_string(index=False))\n\nprint('\\n' + '=' * 80)\nprint('TABLE 3.2: Object Detection — Published Benchmarks (BDD100K val)')\nprint('=' * 80)\nprint(bdd_literature.to_string(index=False))\n\n# Compare our results with literature\nif results_table:\n    print('\\n' + '=' * 80)\n    print('TABLE 3.3: Our Results vs Literature (BDD100K val)')\n    print('=' * 80)\n    our_df = pd.DataFrame(results_table)\n    print(our_df[['Model', 'mAP@0.5', 'mAP@0.5:0.95', 'FPS']].to_string(index=False))\n    print('\\nNote: Our models trained for 50 epochs on BDD100K train split.')\n    print('Published benchmarks use full training schedules and larger model variants.')\n\n# Save\ncoco_literature.to_csv(f'{RESULTS_DIR}/literature_coco_detection.csv', index=False)\nbdd_literature.to_csv(f'{RESULTS_DIR}/literature_bdd_detection.csv', index=False)\nprint(f'\\nLiterature tables saved to: {RESULTS_DIR}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "print(f'\\nPhase 3 results saved to: {RESULTS_DIR}')\nprint('Sections completed:')\nprint('  3.1-3.6: Model training (YOLOv8n baseline/augmented, RT-DETR)')\nprint('  3.7-3.8: Evaluation and visualization')\nprint('  3.9: Cross-condition robustness analysis')\nprint('  3.10: Literature comparison with published benchmarks')\nprint('Next: Open Phase4_Face_Recognition.ipynb')",
   "execution_count": null,
   "outputs": []
  }
 ]
}